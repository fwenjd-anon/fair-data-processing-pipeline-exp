{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random,time,csv\n",
    "import numpy as np\n",
    "import math,copy,os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9769, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/adult.data.csv')\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## Drop categorical features\n",
    "dataset_orig = dataset_orig.drop(['workclass','fnlwgt','education','marital-status','occupation','relationship','native-country'],axis=1)\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == ' Male', 1, 0)\n",
    "dataset_orig['race'] = np.where(dataset_orig['race'] != ' White', 0, 1)\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == ' <=50K', 0, 1)\n",
    "\n",
    "\n",
    "## Discretize age\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= 70, 70, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 60 ) & (dataset_orig['age'] < 70), 60, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 50 ) & (dataset_orig['age'] < 60), 50, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 40 ) & (dataset_orig['age'] < 50), 40, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 30 ) & (dataset_orig['age'] < 40), 30, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 20 ) & (dataset_orig['age'] < 30), 20, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where((dataset_orig['age'] >= 10 ) & (dataset_orig['age'] < 10), 10, dataset_orig['age'])\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] < 10, 0, dataset_orig['age'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "\n",
    "\n",
    "\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8715 1054\n"
     ]
    }
   ],
   "source": [
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][3] == 0: ## index of Sex is 3, Race is 2\n",
    "        row_[0][3] = 1\n",
    "    else:\n",
    "        row_[0][3] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9536 233\n"
     ]
    }
   ],
   "source": [
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][2] == 0: ## index of Sex is 3, Race is 2\n",
    "        row_[0][2] = 1\n",
    "    else:\n",
    "        row_[0][2] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "\n",
    "\n",
    "\n",
    "## Drop categorical features\n",
    "## Removed two duplicate coumns - 'decile_score','priors_count'\n",
    "dataset_orig = dataset_orig.drop(['id','name','first','last','compas_screening_date',\n",
    "                                  'dob','age','juv_fel_count','decile_score',\n",
    "                                  'juv_misd_count','juv_other_count','days_b_screening_arrest',\n",
    "                                  'c_jail_in','c_jail_out','c_case_number','c_offense_date','c_arrest_date',\n",
    "                                  'c_days_from_compas','c_charge_desc','is_recid','r_case_number','r_charge_degree',\n",
    "                                  'r_days_from_arrest','r_offense_date','r_charge_desc','r_jail_in','r_jail_out',\n",
    "                                  'violent_recid','is_violent_recid','vr_case_number','vr_charge_degree','vr_offense_date',\n",
    "                                  'vr_charge_desc','type_of_assessment','decile_score','score_text','screening_date',\n",
    "                                  'v_type_of_assessment','v_decile_score','v_score_text','v_screening_date','in_custody',\n",
    "                                  'out_custody','start','end','event'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'Female', 1, 0)\n",
    "dataset_orig['race'] = np.where(dataset_orig['race'] != 'Caucasian', 0, 1)\n",
    "dataset_orig['priors_count'] = np.where((dataset_orig['priors_count'] >= 1 ) & (dataset_orig['priors_count'] <= 3), 3, dataset_orig['priors_count'])\n",
    "dataset_orig['priors_count'] = np.where(dataset_orig['priors_count'] > 3, 4, dataset_orig['priors_count'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == 'Greater than 45',45,dataset_orig['age_cat'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == '25 - 45', 25, dataset_orig['age_cat'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == 'Less than 25', 0, dataset_orig['age_cat'])\n",
    "dataset_orig['c_charge_degree'] = np.where(dataset_orig['c_charge_degree'] == 'F', 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Rename class column\n",
    "dataset_orig.rename(index=str, columns={\"two_year_recid\": \"Probability\"}, inplace=True)\n",
    "\n",
    "# Here did not rec means 0 is the favorable lable\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 0, 1, 0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166 277\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Sex is 0, Race is 2\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443 0\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][2] == 0: ## index of Sex is 0, Race is 2\n",
    "        row_[0][2] = 1\n",
    "    else:\n",
    "        row_[0][2] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/GermanData.csv')\n",
    "\n",
    "## Drop categorical features\n",
    "dataset_orig = dataset_orig.drop(['1','2','4','5','8','10','11','12','14','15','16','17','18','19','20'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A91', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A92', 0, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A93', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A94', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A95', 0, dataset_orig['sex'])\n",
    "\n",
    "# mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "# dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 1, 0)\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= 25, 1, 0)\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A30', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A31', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A32', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A33', 2, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A34', 3, dataset_orig['credit_history'])\n",
    "\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A61', 1, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A62', 1, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A63', 2, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A64', 2, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A65', 3, dataset_orig['savings'])\n",
    "\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A72', 1, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A73', 1, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A74', 2, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A75', 2, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A71', 3, dataset_orig['employment'])\n",
    "\n",
    "\n",
    "\n",
    "## ADD Columns\n",
    "dataset_orig['credit_history=Delay'] = 0\n",
    "dataset_orig['credit_history=None/Paid'] = 0\n",
    "dataset_orig['credit_history=Other'] = 0\n",
    "\n",
    "dataset_orig['credit_history=Delay'] = np.where(dataset_orig['credit_history'] == 1, 1, dataset_orig['credit_history=Delay'])\n",
    "dataset_orig['credit_history=None/Paid'] = np.where(dataset_orig['credit_history'] == 2, 1, dataset_orig['credit_history=None/Paid'])\n",
    "dataset_orig['credit_history=Other'] = np.where(dataset_orig['credit_history'] == 3, 1, dataset_orig['credit_history=Other'])\n",
    "\n",
    "dataset_orig['savings=500+'] = 0\n",
    "dataset_orig['savings=<500'] = 0\n",
    "dataset_orig['savings=Unknown/None'] = 0\n",
    "\n",
    "dataset_orig['savings=500+'] = np.where(dataset_orig['savings'] == 1, 1, dataset_orig['savings=500+'])\n",
    "dataset_orig['savings=<500'] = np.where(dataset_orig['savings'] == 2, 1, dataset_orig['savings=<500'])\n",
    "dataset_orig['savings=Unknown/None'] = np.where(dataset_orig['savings'] == 3, 1, dataset_orig['savings=Unknown/None'])\n",
    "\n",
    "dataset_orig['employment=1-4 years'] = 0\n",
    "dataset_orig['employment=4+ years'] = 0\n",
    "dataset_orig['employment=Unemployed'] = 0\n",
    "\n",
    "dataset_orig['employment=1-4 years'] = np.where(dataset_orig['employment'] == 1, 1, dataset_orig['employment=1-4 years'])\n",
    "dataset_orig['employment=4+ years'] = np.where(dataset_orig['employment'] == 2, 1, dataset_orig['employment=4+ years'])\n",
    "dataset_orig['employment=Unemployed'] = np.where(dataset_orig['employment'] == 3, 1, dataset_orig['employment=Unemployed'])\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig.drop(['credit_history','savings','employment'],axis=1)\n",
    "## In dataset 1 means good, 2 means bad for probability. I change 2 to 0\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 2, 0, 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 9\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Sex is 0\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 25)\n"
     ]
    }
   ],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/default_of_credit_card_clients_first_row_removed.csv')\n",
    "\n",
    "\n",
    "\n",
    "## Drop categorical features\n",
    "\n",
    "\n",
    "## Change column values\n",
    "\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 2, 0,1)\n",
    "\n",
    "protected_attribute = 'sex'\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5989 11\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Sex is 0\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart-Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/processed.cleveland.data.csv')\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## calculate mean of age column\n",
    "mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 0, 1)\n",
    "\n",
    "## Make goal column binary\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] > 0, 1, 0)\n",
    "\n",
    "protected_attribute = 'age'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 5\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Age is 0\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2233, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/bank.csv')\n",
    "\n",
    "## Drop categorical features\n",
    "\n",
    "dataset_orig = dataset_orig.drop(['job','marital','education','contact','month','poutcome'],axis=1)\n",
    "\n",
    "dataset_orig['default'] = np.where(dataset_orig['default'] == 'no', 0, 1)\n",
    "dataset_orig['housing'] = np.where(dataset_orig['housing'] == 'no', 0, 1)\n",
    "dataset_orig['loan'] = np.where(dataset_orig['loan'] == 'no', 0, 1)\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 'yes', 1, 0)\n",
    "\n",
    "mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= 30, 1, 0)\n",
    "\n",
    "\n",
    "protected_attribute = 'age'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787 446\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Age is 0\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61503, 105)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/Home Credit Default Risk.csv')\n",
    "\n",
    "## Drop categorical features\n",
    "\n",
    "# dataset_orig = dataset_orig.fillna(0)\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig.drop(['SK_ID_CURR','NAME_CONTRACT_TYPE','FLAG_OWN_CAR','FLAG_OWN_REALTY',\n",
    "                                  'NAME_TYPE_SUITE','NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE' ,\n",
    "                                  'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE','OCCUPATION_TYPE',\n",
    "                                  'WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE','FONDKAPREMONT_MODE',\n",
    "                                  'HOUSETYPE_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE',\n",
    "                                  'DAYS_LAST_PHONE_CHANGE'],axis=1)\n",
    "\n",
    "# dataset_orig = dataset_orig.dropna()\n",
    "dataset_orig = dataset_orig.fillna(0)\n",
    "# ## Change symbolics to numerics\n",
    "dataset_orig['CODE_GENDER'] = np.where(dataset_orig['CODE_GENDER'] == 'M', 1, 0)\n",
    "\n",
    "protected_attribute = 'CODE_GENDER'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37290 24213\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][1] == 0: ## index of Age is 0\n",
    "        row_[0][1] = 1\n",
    "    else:\n",
    "        row_[0][1] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/student/Student.csv')\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## Drop categorical features\n",
    "dataset_orig = dataset_orig.drop(['school','address', 'famsize', 'Pstatus','Mjob', 'Fjob', 'reason', 'guardian'],axis=1)\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'M', 1, 0)\n",
    "dataset_orig['schoolsup'] = np.where(dataset_orig['schoolsup'] == 'yes', 1, 0)\n",
    "dataset_orig['famsup'] = np.where(dataset_orig['famsup'] == 'yes', 1, 0)\n",
    "dataset_orig['paid'] = np.where(dataset_orig['paid'] == 'yes', 1, 0)\n",
    "dataset_orig['activities'] = np.where(dataset_orig['activities'] == 'yes', 1, 0)\n",
    "dataset_orig['nursery'] = np.where(dataset_orig['nursery'] == 'yes', 1, 0)\n",
    "dataset_orig['higher'] = np.where(dataset_orig['higher'] == 'yes', 1, 0)\n",
    "dataset_orig['internet'] = np.where(dataset_orig['internet'] == 'yes', 1, 0)\n",
    "dataset_orig['romantic'] = np.where(dataset_orig['romantic'] == 'yes', 1, 0)\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] > 12, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "protected_attribute = 'sex'\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 8\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][0] == 0: ## index of Sex is 0\n",
    "        row_[0][0] = 1\n",
    "    else:\n",
    "        row_[0][0] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEPS 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3514, 43)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/MEPS/h181.csv')\n",
    "\n",
    "# ## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns = {'FTSTU53X' : 'FTSTU', 'ACTDTY53' : 'ACTDTY', 'HONRDC53' : 'HONRDC', 'RTHLTH53' : 'RTHLTH',\n",
    "                              'MNHLTH53' : 'MNHLTH', 'CHBRON53' : 'CHBRON', 'JTPAIN53' : 'JTPAIN', 'PREGNT53' : 'PREGNT',\n",
    "                              'WLKLIM53' : 'WLKLIM', 'ACTLIM53' : 'ACTLIM', 'SOCLIM53' : 'SOCLIM', 'COGLIM53' : 'COGLIM',\n",
    "                              'EMPST53' : 'EMPST', 'REGION53' : 'REGION', 'MARRY53X' : 'MARRY', 'AGE53X' : 'AGE',\n",
    "                              'POVCAT15' : 'POVCAT', 'INSCOV15' : 'INSCOV'})\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig[dataset_orig['PANEL'] == 20]\n",
    "dataset_orig = dataset_orig[dataset_orig['REGION'] >= 0] # remove values -1\n",
    "dataset_orig = dataset_orig[dataset_orig['AGE'] >= 0] # remove values -1\n",
    "dataset_orig = dataset_orig[dataset_orig['MARRY'] >= 0] # remove values -1, -7, -8, -9\n",
    "dataset_orig = dataset_orig[dataset_orig['ASTHDX'] >= 0] # remove values -1, -7, -8, -9\n",
    "dataset_orig = dataset_orig[(dataset_orig[['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                             'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                             'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                             'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                             'PHQ242','EMPST','POVCAT','INSCOV']] >= -1).all(1)]\n",
    "\n",
    "# ## Change symbolics to numerics\n",
    "dataset_orig['RACEV2X'] = np.where((dataset_orig['HISPANX'] == 2 ) & (dataset_orig['RACEV2X'] == 1), 1, dataset_orig['RACEV2X'])\n",
    "dataset_orig['RACEV2X'] = np.where(dataset_orig['RACEV2X'] != 1 , 0, dataset_orig['RACEV2X'])\n",
    "dataset_orig = dataset_orig.rename(columns={\"RACEV2X\" : \"RACE\"})\n",
    "# dataset_orig['UTILIZATION'] = np.where(dataset_orig['UTILIZATION'] >= 10, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "def utilization(row):\n",
    "        return row['OBTOTV15'] + row['OPTOTV15'] + row['ERTOT15'] + row['IPNGTD15'] + row['HHTOTD15']\n",
    "\n",
    "dataset_orig['TOTEXP15'] = dataset_orig.apply(lambda row: utilization(row), axis=1)\n",
    "lessE = dataset_orig['TOTEXP15'] < 10.0\n",
    "dataset_orig.loc[lessE,'TOTEXP15'] = 0.0\n",
    "moreE = dataset_orig['TOTEXP15'] >= 10.0\n",
    "dataset_orig.loc[moreE,'TOTEXP15'] = 1.0\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns = {'TOTEXP15' : 'UTILIZATION'})\n",
    "\n",
    "dataset_orig = dataset_orig[['REGION','AGE','SEX','RACE','MARRY',\n",
    "                                 'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                                 'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                                 'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                                 'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42', 'ADSMOK42',\n",
    "                                 'PCS42','MCS42','K6SUM42','PHQ242','EMPST','POVCAT','INSCOV','UTILIZATION', 'PERWT15F']]\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns={\"UTILIZATION\": \"Probability\",\"RACE\" : \"race\"})\n",
    "protected_attribute = 'race'\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3428 86\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][3] == 0: ## index of race is 3\n",
    "        row_[0][3] = 1\n",
    "    else:\n",
    "        row_[0][3] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEPS 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jchakra\\python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3135, 43)\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = pd.read_csv('../data/MEPS/h192.csv')\n",
    "\n",
    "# ## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns = {'FTSTU53X' : 'FTSTU', 'ACTDTY53' : 'ACTDTY', 'HONRDC53' : 'HONRDC', 'RTHLTH53' : 'RTHLTH',\n",
    "                              'MNHLTH53' : 'MNHLTH', 'CHBRON53' : 'CHBRON', 'JTPAIN53' : 'JTPAIN', 'PREGNT53' : 'PREGNT',\n",
    "                              'WLKLIM53' : 'WLKLIM', 'ACTLIM53' : 'ACTLIM', 'SOCLIM53' : 'SOCLIM', 'COGLIM53' : 'COGLIM',\n",
    "                              'EMPST53' : 'EMPST', 'REGION53' : 'REGION', 'MARRY53X' : 'MARRY', 'AGE53X' : 'AGE',\n",
    "                              'POVCAT16' : 'POVCAT', 'INSCOV16' : 'INSCOV'})\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig[dataset_orig['PANEL'] == 21]\n",
    "dataset_orig = dataset_orig[dataset_orig['REGION'] >= 0] # remove values -1\n",
    "dataset_orig = dataset_orig[dataset_orig['AGE'] >= 0] # remove values -1\n",
    "dataset_orig = dataset_orig[dataset_orig['MARRY'] >= 0] # remove values -1, -7, -8, -9\n",
    "dataset_orig = dataset_orig[dataset_orig['ASTHDX'] >= 0] # remove values -1, -7, -8, -9\n",
    "dataset_orig = dataset_orig[(dataset_orig[['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                         'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                         'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                         'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                         'PHQ242','EMPST','POVCAT','INSCOV']] >= -1).all(1)]\n",
    "\n",
    "# ## Change symbolics to numerics\n",
    "dataset_orig['RACEV2X'] = np.where((dataset_orig['HISPANX'] == 2 ) & (dataset_orig['RACEV2X'] == 1), 1, dataset_orig['RACEV2X'])\n",
    "dataset_orig['RACEV2X'] = np.where(dataset_orig['RACEV2X'] != 1 , 0, dataset_orig['RACEV2X'])\n",
    "dataset_orig = dataset_orig.rename(columns={\"RACEV2X\" : \"RACE\"})\n",
    "# dataset_orig['UTILIZATION'] = np.where(dataset_orig['UTILIZATION'] >= 10, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "def utilization(row):\n",
    "        return row['OBTOTV16'] + row['OPTOTV16'] + row['ERTOT16'] + row['IPNGTD16'] + row['HHTOTD16']\n",
    "\n",
    "dataset_orig['TOTEXP16'] = dataset_orig.apply(lambda row: utilization(row), axis=1)\n",
    "lessE = dataset_orig['TOTEXP16'] < 10.0\n",
    "dataset_orig.loc[lessE,'TOTEXP16'] = 0.0\n",
    "moreE = dataset_orig['TOTEXP16'] >= 10.0\n",
    "dataset_orig.loc[moreE,'TOTEXP16'] = 1.0\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns = {'TOTEXP16' : 'UTILIZATION'})\n",
    "\n",
    "dataset_orig = dataset_orig[['REGION','AGE','SEX','RACE','MARRY',\n",
    "                                 'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                                 'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                                 'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                                 'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42', 'ADSMOK42',\n",
    "                                 'PCS42','MCS42','K6SUM42','PHQ242','EMPST','POVCAT','INSCOV','UTILIZATION', 'PERWT16F']]\n",
    "\n",
    "dataset_orig = dataset_orig.rename(columns={\"UTILIZATION\": \"Probability\",\"RACE\" : \"race\"})\n",
    "protected_attribute = 'race'\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)\n",
    "\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X, y= dataset_orig.loc[:, dataset_orig.columns != 'Probability'], dataset_orig['Probability']\n",
    "clf = LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=100) # LSR\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.2, shuffle = True)\n",
    "X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'], dataset_orig_train['Probability']\n",
    "X_test , y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'], dataset_orig_test['Probability']\n",
    "clf.fit(X_train, y_train)\n",
    "print(dataset_orig_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3049 86\n"
     ]
    }
   ],
   "source": [
    "# Create new test by switching the value of prottected attribute\n",
    "same , not_same = 0,0\n",
    "for index,row in dataset_orig_test.iterrows():\n",
    "    row_ = [row.values[0:len(row.values)-1]]    \n",
    "    y_normal = clf.predict(row_)\n",
    "    # Here protected attribute value gets switched\n",
    "    if row_[0][3] == 0: ## index of race is 3\n",
    "        row_[0][3] = 1\n",
    "    else:\n",
    "        row_[0][3] = 0    \n",
    "    y_reverse = clf.predict(row_)\n",
    "    if y_normal[0] != y_reverse[0]:\n",
    "        not_same += 1\n",
    "    else:\n",
    "        same += 1\n",
    "print(same , not_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
